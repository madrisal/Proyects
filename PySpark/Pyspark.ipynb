{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType, IntegerType, NumericType\n",
    "from pyspark.sql.functions import col, sum, when\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, Imputer, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor, DecisionTreeRegressor\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('proyecto_m6').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos y schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv'\n",
    "csv_path = 'diamonds.csv'\n",
    "with open(csv_path, 'wb') as file:\n",
    "    file.write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('carat', FloatType(), True),\n",
    "    StructField('cut', StringType(), True),\n",
    "    StructField('color', StringType(), True),\n",
    "    StructField('clarity', StringType(), True),\n",
    "    StructField('depth', FloatType(), True),\n",
    "    StructField('table', FloatType(), True),\n",
    "    StructField('price', IntegerType(), True),\n",
    "    StructField('x', FloatType(), True),\n",
    "    StructField('y', FloatType(), True),\n",
    "    StructField('z', FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(csv_path, header=True, inferSchema=False, schema=schema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|carat|cut|color|clarity|depth|table|price|  x|  y|  z|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|    0|  0|    0|      0|    0|    0|    0|  0|  0|  0|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compruebo nulos\n",
    "df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.7979397459442544</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>61.749404890324215</td>\n",
       "      <td>57.457183908399585</td>\n",
       "      <td>3932.799721913237</td>\n",
       "      <td>5.731157212872659</td>\n",
       "      <td>5.734525955793015</td>\n",
       "      <td>3.5387337920972493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>0.474011242836904</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.432621320665403</td>\n",
       "      <td>2.2344905638396657</td>\n",
       "      <td>3989.439738146397</td>\n",
       "      <td>1.1217607437465076</td>\n",
       "      <td>1.1421346736743894</td>\n",
       "      <td>0.705698843275196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Fair</td>\n",
       "      <td>D</td>\n",
       "      <td>I1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>5.01</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>18823</td>\n",
       "      <td>10.74</td>\n",
       "      <td>58.9</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary               carat        cut  color clarity               depth  \\\n",
       "0   count               53940      53940  53940   53940               53940   \n",
       "1    mean  0.7979397459442544       None   None    None  61.749404890324215   \n",
       "2  stddev   0.474011242836904       None   None    None   1.432621320665403   \n",
       "3     min                 0.2       Fair      D      I1                43.0   \n",
       "4     max                5.01  Very Good      J    VVS2                79.0   \n",
       "\n",
       "                table              price                   x  \\\n",
       "0               53940              53940               53940   \n",
       "1  57.457183908399585  3932.799721913237   5.731157212872659   \n",
       "2  2.2344905638396657  3989.439738146397  1.1217607437465076   \n",
       "3                43.0                326                 0.0   \n",
       "4                95.0              18823               10.74   \n",
       "\n",
       "                    y                   z  \n",
       "0               53940               53940  \n",
       "1   5.734525955793015  3.5387337920972493  \n",
       "2  1.1421346736743894   0.705698843275196  \n",
       "3                 0.0                 0.0  \n",
       "4                58.9                31.8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las columnas x, y, z, considero los valores 0 como nulos y los reemplazo por None para aplicar imputer a esas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|carat|cut|color|clarity|depth|table|price|  x|  y|  z|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|    0|  0|    0|      0|    0|    0|    0|  8|  7| 20|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('x', when(df['x'] == 0, None).otherwise(df['x'])) \\\n",
    ".withColumn('y', when(df['y'] == 0, None).otherwise(df['y'])) \\\n",
    ".withColumn('z', when(df['z'] == 0, None).otherwise(df['z']))\n",
    "\n",
    "df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|  cut|color|clarity|depth|table|label|   x|   y|   z|\n",
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DF para regresión del precio.\n",
    "# Renombro la columna price por label.\n",
    "df1 = df.withColumnRenamed('price', 'label')\n",
    "df1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat', 'depth', 'table', 'x', 'y', 'z']\n",
      "['cut', 'color', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [field.name for field in df1.schema.fields if isinstance(field.dataType, NumericType) and field.name != 'label']\n",
    "categorical_cols = [field.name for field in df1.schema.fields if isinstance(field.dataType, StringType)]\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indexación de columnas categóricas con StringIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed', 'color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + '_indexed', handleInvalid='keep') for c in categorical_cols\n",
    "]\n",
    "categorical_cols_indexed = [c + '_indexed' for c in categorical_cols]\n",
    "print(categorical_cols_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codificación de las columnas categóricas ya indexadas con OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed_onehot', 'color_indexed_onehot', 'clarity_indexed_onehot']\n"
     ]
    }
   ],
   "source": [
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + '_onehot') \n",
    "    for c in categorical_cols_indexed\n",
    "    ]\n",
    "categorical_cols_onehot = [c + '_onehot' for c in categorical_cols_indexed]\n",
    "print(categorical_cols_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imputación de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat_imputed', 'depth_imputed', 'table_imputed', 'x_imputed', 'y_imputed', 'z_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputo la media a los nulos de las columnas numéricas, a las categóricas no es necesario ya que no tienen NaN's.\n",
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + '_imputed' for c in numerical_cols],\n",
    "    strategy='mean'\n",
    ")\n",
    "numerical_cols_imputed = [c + '_imputed' for c in numerical_cols]\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalización de datos con StandarScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplico el scaler a las columnas numéricas.\n",
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol='numeric_features'\n",
    ")\n",
    "scaler = StandardScaler(\n",
    "    inputCol='numeric_features',\n",
    "    outputCol='numeric_features_scaled'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numeric_features_scaled', 'cut_indexed_onehot', 'color_indexed_onehot', 'clarity_indexed_onehot']\n"
     ]
    }
   ],
   "source": [
    "all_columns = ['numeric_features_scaled'] + categorical_cols_onehot\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensamblar las columnas numéricas y categóricas para obtener features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_all = VectorAssembler(\n",
    "    inputCols=all_columns,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bucle para probar varios modelos de regresión con particionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 con LinearRegression: 0.9225571268177755\n",
      "R2 con DecisionTreeRegressor: 0.9049996572272508\n",
      "R2 con RandomForestRegressor: 0.9114267936861328\n",
      "R2 con GBTRegressor: 0.9639392749178024\n"
     ]
    }
   ],
   "source": [
    "df_train1, df_test1 = df1.randomSplit([0.8, 0.2], seed=42)\n",
    "regressors = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor(), GBTRegressor()]\n",
    "\n",
    "for regressor in regressors:\n",
    "    pipeline_reg = Pipeline(stages=[\n",
    "        *indexers_features,\n",
    "        *encoders_onehot,\n",
    "        imputer_numerical,\n",
    "        assembler_numerical,\n",
    "        scaler,\n",
    "        assembler_all,\n",
    "        regressor\n",
    "    ])\n",
    "    \n",
    "    pipeline_regresion = pipeline_reg.fit(df_train1)\n",
    "    df1_pred = pipeline_regresion.transform(df_test1)\n",
    "    \n",
    "    evaluator = RegressionEvaluator(metricName=\"r2\")\n",
    "    r2 = evaluator.evaluate(df1_pred)\n",
    "    \n",
    "    print(f\"R2 con {regressor.__class__.__name__}: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParamGridBuilder y CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor= GBTRegressor()\n",
    "\n",
    "pipeline_cross1 = Pipeline(stages=[\n",
    "    *indexers_features,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    best_regressor\n",
    "])\n",
    "\n",
    "paramGrid1 = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(best_regressor.maxIter, [10, 20]) # Solo pruebo con 2 parámetros para reducir tiempo de ejecución.\n",
    "    .addGrid(best_regressor.maxDepth, [5, 10])\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTRegressionModel: uid=GBTRegressor_d884df60507b, numTrees=20, numFeatures=26\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Tarda 2 minutos\n",
    "crossval1 = CrossValidator(\n",
    "    estimator=pipeline_cross1,\n",
    "    estimatorParamMaps= paramGrid1,\n",
    "    evaluator= RegressionEvaluator(metricName='r2'),\n",
    "    parallelism=4,\n",
    "    seed=42  \n",
    ")\n",
    "cross1_model= crossval1.fit(df_train1)\n",
    "best_model = cross1_model.bestModel\n",
    "best_gbt = best_model.stages[-1]\n",
    "print(best_gbt)\n",
    "print(best_gbt.getNumTrees)\n",
    "print(best_gbt.getOrDefault('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modelo elegido para regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 0.9741729088799557\n",
      "mae 335.22433062772063\n",
      "mse 420214.8768759756\n",
      "rmse 648.2398297512855\n"
     ]
    }
   ],
   "source": [
    "regressor_final= GBTRegressor(maxIter=20, maxDepth=10, seed=42)\n",
    "\n",
    "pipeline_GBT = Pipeline(stages = [\n",
    "    *indexers_features,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    regressor_final\n",
    "])\n",
    "\n",
    "pipeline_reg_final = pipeline_GBT.fit(df_train1)\n",
    "pred_GBT = pipeline_reg_final.transform(df_test1)\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(metricName='r2')\n",
    "evaluator_mae = RegressionEvaluator(metricName='mae')\n",
    "evaluator_mse = RegressionEvaluator(metricName='mse')\n",
    "evaluator_rmse = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "print('r2', evaluator_r2.evaluate(pred_GBT))\n",
    "print('mae', evaluator_mae.evaluate(pred_GBT))\n",
    "print('mse', evaluator_mse.evaluate(pred_GBT))\n",
    "print('rmse', evaluator_rmse.evaluate(pred_GBT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|  cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "+-----+-----+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DF para clasificación del corte\n",
    "df2 = df.select(\"*\")\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
      "['color', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [field.name for field in df2.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "categorical_cols = [field.name for field in df2.schema.fields if isinstance(field.dataType, StringType) and field.name != 'cut']\n",
    "label_col = 'cut'\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indexación de la columna a predecir y de las columnas categóricas con StringIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_label = StringIndexer(\n",
    "    inputCol=label_col,\n",
    "    outputCol='label',\n",
    "    handleInvalid='keep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + '_indexed', handleInvalid='keep') for c in categorical_cols\n",
    "]\n",
    "categorical_cols_indexed = [c + '_indexed' for c in categorical_cols]\n",
    "print(categorical_cols_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codificación de las columnas categóricas ya indexadas con OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_indexed_onehot', 'clarity_indexed_onehot']\n"
     ]
    }
   ],
   "source": [
    "# He comprobado que las columnas categóricas no contienen valores nulos, no es necesario hacer imputer.\n",
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + '_onehot') \n",
    "    for c in categorical_cols_indexed\n",
    "    ]\n",
    "categorical_cols_onehot = [c + '_onehot' for c in categorical_cols_indexed]\n",
    "print(categorical_cols_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imputación de valores nulos de las columnas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat_imputed', 'depth_imputed', 'table_imputed', 'price_imputed', 'x_imputed', 'y_imputed', 'z_imputed']\n"
     ]
    }
   ],
   "source": [
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + '_imputed' for c in numerical_cols],\n",
    "    strategy='mean'\n",
    ")\n",
    "numerical_cols_imputed = [c + '_imputed' for c in numerical_cols]\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Escalado de datos con MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numeric_features_scaled', 'color_indexed_onehot', 'clarity_indexed_onehot']\n"
     ]
    }
   ],
   "source": [
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol='numeric_features'\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol='numeric_features',\n",
    "    outputCol='numeric_features_scaled'\n",
    ")\n",
    "all_columns = ['numeric_features_scaled'] + categorical_cols_onehot\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensamblar las columnas numéricas y categóricas para obtener features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_all = VectorAssembler(\n",
    "    inputCols=all_columns,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con LogisticRegression: 0.6481532651745417\n",
      "Accuracy con DecisionTreeClassifier: 0.7046145344017685\n",
      "Accuracy con RandomForestClassifier: 0.6927327991157778\n"
     ]
    }
   ],
   "source": [
    "df_train2, df_test2 = df2.randomSplit([0.8, 0.2], seed=42)\n",
    "classifiers = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipeline_clas = Pipeline(stages=[\n",
    "        indexer_label,\n",
    "        *indexers_features,\n",
    "        *encoders_onehot,\n",
    "        imputer_numerical,\n",
    "        assembler_numerical,\n",
    "        scaler,\n",
    "        assembler_all,\n",
    "        classifier])\n",
    "        \n",
    "    model = pipeline_clas.fit(df_train2)\n",
    "    df2_pred = model.transform(df_test2)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(df2_pred)\n",
    "    \n",
    "    print(f\"Accuracy con {classifier.__class__.__name__}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParamGridBuilder y CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = DecisionTreeClassifier()\n",
    "\n",
    "pipeline_cross2 = Pipeline(stages=[\n",
    "    indexer_label,\n",
    "    *indexers_features,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    best_classifier])\n",
    "\n",
    "paramGrid2 = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(best_classifier.maxDepth,[10, 20])\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_c89ec50a4457, depth=10, numNodes=865, numClasses=6, numFeatures=22\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "crossval2 = CrossValidator(estimator=pipeline_cross2,\n",
    "                          estimatorParamMaps=paramGrid2,\n",
    "                          evaluator=MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          parallelism= 4,\n",
    "                          seed= 4)\n",
    "\n",
    "cv_model = crossval2.fit(df_train2)\n",
    "best_model_class = cv_model.bestModel\n",
    "best_tree = best_model_class.stages[-1]\n",
    "print(best_tree)\n",
    "print(best_tree.getMaxDepth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modelo elegido para clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.721101593442019\n",
      "f1 0.7005178358023688\n",
      "precision 0.7095851859626563\n",
      "recall 0.721101593442019\n"
     ]
    }
   ],
   "source": [
    "classifier_final = DecisionTreeClassifier(maxDepth=10)\n",
    "\n",
    "pipeline_tree = Pipeline(stages=[\n",
    "    indexer_label,\n",
    "    *indexers_features,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    classifier_final])\n",
    "\n",
    "pipeline_cl_final = pipeline_tree.fit(df_train2)\n",
    "pred_tree = pipeline_cl_final.transform(df_test2)\n",
    "\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "\n",
    "print('accuracy', evaluator_accuracy.evaluate(pred_tree))\n",
    "print('f1', evaluator_f1.evaluate(pred_tree))\n",
    "print('precision', evaluator_precision.evaluate(pred_tree))\n",
    "print('recall', evaluator_recall.evaluate(pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MultiLayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_pred.select(\"features\").first()[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7445887445887446\n",
      "f1 0.7389614986861559\n",
      "precision 0.7380184703437936\n",
      "recall 0.7445887445887446\n"
     ]
    }
   ],
   "source": [
    "classifier_MPC = MultilayerPerceptronClassifier(layers=[22,10,5], maxIter=1000, seed=42)\n",
    "\n",
    "pipeline_MPC = Pipeline(stages=[\n",
    "    indexer_label,\n",
    "    *indexers_features,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    classifier_MPC\n",
    "])\n",
    "\n",
    "pipeline_MPC_final= pipeline_MPC.fit(df_train2)\n",
    "pred_MPC = pipeline_MPC_final.transform(df_test2)\n",
    "\n",
    "print('accuracy', evaluator_accuracy.evaluate(pred_MPC))\n",
    "print('f1', evaluator_f1.evaluate(pred_MPC))\n",
    "print('precision', evaluator_precision.evaluate(pred_MPC))\n",
    "print('recall', evaluator_recall.evaluate(pred_MPC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones\n",
    "* El modelo de regresión obtiene un 0.97 de precisión, explica bien la variación de precios de los diamantes.\n",
    "* En la clasificación no he conseguido un modelo con buena precisión, obtiene un 0.71 de exactitud al clasificar los 5 tipos de cortes de diamantes. Si se ajusta el desbalanceo entre las clases podría mejorar.\n",
    "* La red neuronal supera ligeramente a los otros modelos de clasificación, ajustando los hiperparámetros mejoraría pero no lo suficiente como para que compense la exigencia de recursos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
